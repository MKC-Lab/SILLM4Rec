{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from matrix import *\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_Processor:\n",
    "    def __init__(self, meta_data_path, review_data_path, test_data_path, api_key, base_url):\n",
    "        self.meta_data_path = meta_data_path\n",
    "        self.review_data_path = review_data_path\n",
    "        self.test_data_path = test_data_path\n",
    "        self.api_key = api_key\n",
    "        self.base_url = base_url\n",
    "        self.client = OpenAI(api_key=self.api_key, base_url=self.base_url)\n",
    "\n",
    "    def select_MAIN_image(self, images):\n",
    "        if str(images) != 'nan':\n",
    "            try:\n",
    "                # 从images中选择variant为MAIN的图片, 如果没有MAIN的图片，选择第一张\n",
    "                for image in images:\n",
    "                    if image['variant'] == 'MAIN':\n",
    "                        return image['hi_res']\n",
    "                return images[0]['hi_res']\n",
    "            except:\n",
    "                return None\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def get_Images_from_all_items(self):\n",
    "        # 从meta_data中获取所有item的images\n",
    "        meta_data = pd.read_parquet(self.meta_data_path)\n",
    "        all_images = []\n",
    "        for i in range(len(meta_data)):\n",
    "            item = meta_data.iloc[i]\n",
    "            all_images.append(self.select_MAIN_image(item['images']))\n",
    "        return all_images\n",
    "\n",
    "    def convert_images_to_text(self, system_prompt, user_prompt, image_url, model=\"qwen-vl-plus-latest\"):\n",
    "        if image_url is None:\n",
    "            return 'None'\n",
    "        completion = self.client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"system\", \"content\": system_prompt},\n",
    "                      {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": user_prompt},\n",
    "                                                   {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}}]}\n",
    "                      ])\n",
    "        return completion.choices[0].message.content\n",
    "\n",
    "    def save_all_images_to_text(self, system_prompt, user_prompt, model=\"qwen-vl-plus-latest\", save_path='new_data'):\n",
    "        all_image_url = self.get_Images_from_all_items()\n",
    "        all_image_text = []\n",
    "        for url in all_image_url:\n",
    "            print(url)\n",
    "            try:\n",
    "                answer = self.convert_images_to_text(system_prompt, user_prompt, url, model)\n",
    "                print(answer)\n",
    "                all_image_text.append(answer)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                all_image_text.append('None')\n",
    "        # save to file parquet\n",
    "        df = pd.DataFrame(all_image_text, columns=['image_text'])\n",
    "        df.to_parquet(save_path + '/image_text.parquet')\n",
    "\n",
    "    def check_and_save_images_to_text(self, system_prompt, user_prompt, model=\"qwen-vl-plus-latest\", save_path='new_data'):\n",
    "        if os.path.exists(save_path + '/image_text.parquet'):\n",
    "            image_text = pd.read_parquet(save_path + '/image_text.parquet')\n",
    "            all_image_url = self.get_Images_from_all_items()\n",
    "            for i in range(len(image_text)):\n",
    "                if image_text.iloc[i]['image_text'] == 'None' and all_image_url[i] is not None:\n",
    "                    try:\n",
    "                        print(all_image_url[i])\n",
    "                        answer = self.convert_images_to_text(system_prompt, user_prompt, all_image_url[i], model)\n",
    "                        print(answer)\n",
    "                        image_text.loc[i, 'image_text'] = answer\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                        image_text.loc[i, 'image_text'] = 'None'\n",
    "            # save to file parquet\n",
    "            image_text.to_parquet(save_path + '/image_text.parquet')\n",
    "        else:\n",
    "            self.save_all_images_to_text(system_prompt, user_prompt, model, save_path)\n",
    "\n",
    "    def delete_None_in_details(self, details):\n",
    "        \"\"\"\n",
    "        Delete the None in details\n",
    "        :param details: the details of the item, dict\n",
    "        :return: the details of the item without None\n",
    "        \"\"\"\n",
    "        for key in list(details.keys()):\n",
    "            if type(details[key]) == dict:\n",
    "                for k in list(details[key].keys()):\n",
    "                    if details[key][k] is None:\n",
    "                        del details[key][k]\n",
    "            elif details[key] is None:\n",
    "                del details[key]\n",
    "        return details\n",
    "\n",
    "    def generate_item_prompt_efficient(self, item_id, item_df):\n",
    "        \"\"\"\n",
    "        Generate the item prompt, efficient version, without reading the data again\n",
    "        :param item_id: int, the index of the item\n",
    "        :return: str, the item prompt\n",
    "        \"\"\"\n",
    "        data = item_df[item_df['parent_asin'] == item_id]\n",
    "        item = data.iloc[0]\n",
    "        prompt = f\"Item ID: {item_id}\\n\" \\\n",
    "                 f\"Title: {item['title']}\\n\" \\\n",
    "                 f\"Average Rating: {item['average_rating']} ({item['rating_number']} ratings)\\n\" \\\n",
    "                 f\"Price: {item['price']}\\n\" \\\n",
    "                 f\"Store: {item['store']}\"\n",
    "        #  f\"Categories: {item['categories'].tolist()}\\n\" \\\n",
    "        #  f\"Details: {self.delete_None_in_details(item['details'])}\"\n",
    "        return prompt\n",
    "\n",
    "    def generate_candidate_data(self, user_id, test_data, num_candidates, len_meta_data=711, if_shuffle=False):\n",
    "        # 从meta_data中随机选取num_candidates-1个item，加上用户的最后一个交互item作为候选\n",
    "        # 输出两个，一个是candidate item的list，一个是用户最后一个交互的item的index\n",
    "        history = (test_data[test_data['user_id'] == user_id]['history'].values[0]).tolist()\n",
    "        last_interacted = int(test_data[test_data['user_id'] == user_id]['parent_asin'].values[0])\n",
    "        # 从meta_data中随机选取num_candidates-1个item，保证不在history中\n",
    "        candidate_data = []\n",
    "        for i in range(num_candidates-1):\n",
    "            # 随机生成一个index\n",
    "            index = np.random.randint(0, len_meta_data-1)\n",
    "            while index in history or index in candidate_data or index == last_interacted:\n",
    "                index = np.random.randint(0, len_meta_data-1)\n",
    "            candidate_data.append(index)\n",
    "        # 加上用户的最后一个交互item\n",
    "        candidate_data = [last_interacted] + candidate_data\n",
    "        # 打乱顺序\n",
    "        if if_shuffle:\n",
    "            np.random.shuffle(candidate_data)\n",
    "        # np.random.shuffle(candidate_data)\n",
    "        return candidate_data\n",
    "\n",
    "    def save_candidate_to_test_data(self, len_meta_data=711, is_shuffle=False, name='candidate'):\n",
    "        # 在test_data中加入candidate一列，每个用户的candidate是一个list，包含num_candidates个item的index\n",
    "        test_data = pd.read_parquet(self.test_data_path)\n",
    "        candidate_data = []\n",
    "        for i in range(len(test_data)):\n",
    "            user_id = test_data.iloc[i]['user_id']\n",
    "            candidate = self.generate_candidate_data(user_id, test_data, 10, len_meta_data, is_shuffle)\n",
    "            print('user_id:', user_id)\n",
    "            print('candidate:', candidate)\n",
    "            candidate_data.append(candidate)\n",
    "        test_data[name] = candidate_data\n",
    "        test_data.to_parquet(self.test_data_path)\n",
    "\n",
    "    def re_index_test_data(self):\n",
    "        test_data = pd.read_parquet(self.test_data_path)\n",
    "        test_data = test_data.reset_index(drop=True)\n",
    "        test_data.to_parquet(self.test_data_path)\n",
    "\n",
    "    def re_index_meta_data(self):\n",
    "        meta_data = pd.read_parquet(self.meta_data_path)\n",
    "        meta_data = meta_data.reset_index(drop=True)\n",
    "        meta_data.to_parquet(self.meta_data_path)\n",
    "\n",
    "    def get_history_prompt_for_one_user(self, user_id, meta_data, review_data, test_data, images_data, max_history=15):\n",
    "        # 为一个用户生成用户偏好总结\n",
    "        history = (test_data[test_data['user_id'] == user_id]['history'].values[0]).tolist()\n",
    "        if len(history) > max_history:\n",
    "            history = history[-max_history:]\n",
    "        user_preference_prompt = ''\n",
    "        for i in range(len(history)):\n",
    "            item_id = history[i]\n",
    "            item_index = meta_data[meta_data['parent_asin'] == item_id].index[0]\n",
    "            item_info = self.generate_item_prompt_efficient(item_id, meta_data)\n",
    "            photos_text = images_data.iloc[item_index]['image_text']\n",
    "            user_review = review_data[(review_data['user_id'] == user_id) & (review_data['parent_asin'] == item_id)].iloc[0]\n",
    "            user_preference_prompt += item_info + '\\n' \\\n",
    "                f'Description: {photos_text}\\n' \\\n",
    "                f'User Review: {user_review[\"text\"]}\\n'\\\n",
    "                f'User Rating: {user_review[\"rating\"]}\\n\\n'\n",
    "        return user_preference_prompt\n",
    "\n",
    "    def summariza_preference_for_one_user(self, user_id, meta_data, review_data, test_data, images_data, system_prompt, model=\"qwen2.5-7b-instruct-1m\"):\n",
    "        user_preference_prompt = self.get_history_prompt_for_one_user(user_id, meta_data, review_data, test_data, images_data)\n",
    "        user_prompt = f'Please summarize the user preference with the following information:\\n{user_preference_prompt}'\n",
    "        result = self.client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"system\", \"content\": system_prompt},\n",
    "                      {\"role\": \"user\", \"content\": user_prompt},\n",
    "                      ])\n",
    "        return result.choices[0].message.content\n",
    "\n",
    "    def summarize_user_preference(self, system_prompt, model=\"qwen2.5-7b-instruct-1m\", save_path='new_data'):\n",
    "        meta_data = pd.read_parquet(self.meta_data_path)\n",
    "        review_data = pd.read_parquet(self.review_data_path)\n",
    "        test_data = pd.read_parquet(self.test_data_path)\n",
    "        images_data = pd.read_parquet(save_path + '/image_text.parquet')\n",
    "        # 为每个用户生成用户偏好总结, 并保存到文件, 保存到test_data中 user_preference列\n",
    "        user_preference = []\n",
    "        for i in range(len(test_data)):\n",
    "            user_id = test_data.iloc[i]['user_id']\n",
    "            print('user_id:', user_id)\n",
    "            try:\n",
    "                result = self.summariza_preference_for_one_user(user_id, meta_data, review_data, test_data, images_data, system_prompt, model)\n",
    "                print(result)\n",
    "                user_preference.append(result)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                user_preference.append('None')\n",
    "        test_data['user_preference'] = user_preference\n",
    "        test_data.to_parquet(self.test_data_path)\n",
    "\n",
    "    def get_candidate_prompt_for_one_user(self, user_id, meta_data, test_data, images_data, candidate_name = \"candidate\", reason_data=None):\n",
    "        # 为一个用户生成候选item总结\n",
    "        candidate = (test_data[test_data['user_id'] == user_id][candidate_name].values[0]).tolist()\n",
    "        target = (test_data[test_data['user_id'] == user_id]['parent_asin'].values[0])\n",
    "        target_score = (test_data[test_data['user_id'] == user_id]['rating'].values[0])\n",
    "        candidate_prompt = ''\n",
    "        for i in range(len(candidate)):\n",
    "            item_id = candidate[i]\n",
    "            item_index = meta_data[meta_data['parent_asin'] == item_id].index[0]\n",
    "            item_info = self.generate_item_prompt_efficient(item_id, meta_data)\n",
    "            photos_text = images_data.iloc[item_index]['image_text']\n",
    "            candidate_prompt += item_info + '\\n' \\\n",
    "                f'Photos Text: {photos_text}\\n\\n'\n",
    "        return candidate_prompt, len(candidate), target, target_score\n",
    "\n",
    "    def get_list_from_result(self, result):\n",
    "        # 从openai的返回结果中提取用户的排序结果, 答案中应该有一个list，类似于[1, 2, 3, 4, 5]\n",
    "        # 返回一个list\n",
    "        # 首先尝试用正则表达式提取\n",
    "        result = result.replace('\\n', '')\n",
    "        result = result.replace(' ', '')\n",
    "        pattern = re.compile(r'\\[(.*?)\\]')\n",
    "        match = pattern.search(result)\n",
    "        # 如果匹配不到，通过提取数字来获取\n",
    "        if match is None:\n",
    "            pattern = re.compile(r'\\d+')\n",
    "            match = pattern.findall(result)\n",
    "        else:\n",
    "            match = match.group(1)\n",
    "            match = match.split(',')\n",
    "        # 最终返回的结果type是list\n",
    "        return [int(x) for x in match]\n",
    "\n",
    "    def get_list_from_result_cot(self, result):\n",
    "        \"\"\"\n",
    "        从LLM的返回结果中提取排序列表，特别处理带有思维链(CoT)的结果\n",
    "        结果应该包含类似[1,2,3,4,5,6,7,8,9,10]这样的列表\n",
    "\n",
    "        Args:\n",
    "            result: LLM返回的字符串结果\n",
    "\n",
    "        Returns:\n",
    "            包含整数的列表，例如[1,2,3,4,5,6,7,8,9,10]\n",
    "        \"\"\"\n",
    "        if result is None or not isinstance(result, str):\n",
    "            return []\n",
    "\n",
    "        # 预处理：删除换行符和多余空格\n",
    "        result = result.replace('\\n', ' ').replace('\\t', ' ').replace('*', '')\n",
    "\n",
    "        # 方法1：尝试查找标准列表格式 [x,x,x,...,x]\n",
    "        pattern = re.compile(r'\\[(\\d+(?:\\s*,\\s*\\d+){2,})\\]')  # 至少3个数字的列表模式\n",
    "        matches = pattern.findall(result)\n",
    "\n",
    "        if matches:\n",
    "            # 取最后一个匹配结果，通常CoT后的最终答案在最后\n",
    "            numbers_str = matches[-1]\n",
    "            # 解析数字\n",
    "            try:\n",
    "                numbers = [int(num.strip()) for num in numbers_str.split(',')]\n",
    "                # 检查是否有约10个数字（允许8-12个）\n",
    "                if 8 <= len(numbers) <= 12:\n",
    "                    return numbers\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        return []\n",
    "\n",
    "    def convert_item_id_to_item_score(self, rank_result, target, target_score):\n",
    "        # rank_result 为 list，包含了用户对候选item_id的排序\n",
    "        # target 为用户的目标item_id\n",
    "        # target_score 为用户对目标item的评分\n",
    "        rank_result = [target_score if x == target else 0 for x in rank_result]\n",
    "        if sum(rank_result) == 0:\n",
    "            return 'Error'\n",
    "        return rank_result\n",
    "\n",
    "    def generate_sft_dataset(self, system_prompt, save_path='new_data'):\n",
    "        # 生成sft_dataset\n",
    "        meta_data = pd.read_parquet(self.meta_data_path)\n",
    "        test_data = pd.read_parquet(self.test_data_path)\n",
    "        images_data = pd.read_parquet(save_path + '/image_text.parquet')\n",
    "        sft_dataset = []\n",
    "        for i in range(len(test_data)):\n",
    "            user_id = test_data.iloc[i]['user_id']\n",
    "            print(i, ' User', user_id)\n",
    "            candidate = (test_data.iloc[i]['candidate'].values[0]).tolist()\n",
    "            target = test_data.iloc[i]['parent_asin'].values[0]\n",
    "            # 打乱顺序\n",
    "            np.random.shuffle(candidate)\n",
    "            candidate_prompt = ''\n",
    "            for j in range(len(candidate)):  # 修改i为j以避免与外层循环变量冲突\n",
    "                item_id = candidate[j]\n",
    "                item = meta_data[meta_data['parent_asin'] == item_id].iloc[0]\n",
    "                candidate_prompt += f\"Item ID: {item_id}\\n\" \\\n",
    "                    f\"Title: {item['title']}\\n\" \\\n",
    "                    f\"Average Rating: {item['average_rating']} ({item['rating_number']} ratings)\\n\" \\\n",
    "                    f\"Price: {item['price']}\\n\" \\\n",
    "                    f\"Store: {item['store']}\\n\" \\\n",
    "                    f\"Description: {images_data.iloc[meta_data[meta_data['parent_asin'] == item_id].index[0]]['image_text']}\\n\\n\"\n",
    "            user_preference_prompt = test_data[test_data['user_id'] == user_id]['user_preference'].values[0]\n",
    "            user_prompt = f\"Please rank the following {len(candidate)} items based on user's preference and give back your answer with a form of list of these candidate items'ID :\\n\" \\\n",
    "                f\"User Preference: {user_preference_prompt} \\n\" \\\n",
    "                f\"Candidate Items: \\n{candidate_prompt}\"\n",
    "            # 把候选item中的target item放在第一位\n",
    "            candidate.remove(target)\n",
    "            # 打乱顺序\n",
    "            np.random.shuffle(candidate)\n",
    "            candidate = [target] + candidate\n",
    "            sft = {\"instruction\": system_prompt,\n",
    "                   \"input\": user_prompt,\n",
    "                   \"output\": candidate}  # candidate已经被转换为列表\n",
    "            sft_dataset.append(sft)\n",
    "        # save to file\n",
    "        with open(save_path + '/sft_dataset.json', 'w') as f:\n",
    "            json.dump(sft_dataset, f)\n",
    "\n",
    "\n",
    "    def get_rank_result_for_one_user(self, user_id, meta_data, test_data, images_data, system_prompt, candidate_name=\"candidate\", model=\"qwen2.5-7b-instruct-1m\"):\n",
    "        # ------ My baseline ------\n",
    "        candidate_prompt, candidate_num, target, target_score = self.get_candidate_prompt_for_one_user(user_id, meta_data, test_data, images_data, candidate_name, reason_data=None)\n",
    "        user_preference_prompt = test_data[test_data['user_id'] == user_id]['user_preference'].values[0]\n",
    "        user_prompt = f\"Please rank the following {candidate_num} items based on user's preference and give back your answer with a form of list of these candidate items'ID :\\n \\\n",
    "            User Preference: {user_preference_prompt} \\n \\\n",
    "            Candidate Items: \\n{candidate_prompt}\"\n",
    "        # --------------------------\n",
    "        # print(user_prompt)\n",
    "        result = self.client.chat.completions.create(\n",
    "            model=model,\n",
    "            # temperature=0.2,\n",
    "            messages=[{\"role\": \"system\", \"content\": system_prompt},\n",
    "                      {\"role\": \"user\", \"content\": user_prompt},\n",
    "                      ])\n",
    "        return result.choices[0].message.content, target, target_score\n",
    "\n",
    "    def get_sft_data_for_all_user(self, meta_data, test_data, images_data, system_prompt, rank_result_data, save_path='new_data'):\n",
    "        sft_data = []\n",
    "        for i in range(len(rank_result_data)):\n",
    "            user_id = rank_result_data.iloc[i]['user_id']\n",
    "            rank = rank_result_data.iloc[i]['rank_result']\n",
    "            target = rank_result_data.iloc[i]['target']\n",
    "            target_score = rank_result_data.iloc[i]['target_score']\n",
    "            candidate = test_data[test_data['user_id'] == user_id]['candidate'].values[0]\n",
    "            print('user_id:', user_id)\n",
    "            candidate_prompt, candidate_num, target, target_score = self.get_candidate_prompt_for_one_user(user_id, meta_data, test_data, images_data, candidate_name=\"candidate\", reason_data=None)\n",
    "            user_preference_prompt = test_data[test_data['user_id'] == user_id]['user_preference'].values[0]\n",
    "            user_prompt = f\"Please rank the following {candidate_num} items based on user's preference and give back your answer with a form of list of these candidate items'ID :\\n \\\n",
    "                User Preference: {user_preference_prompt} \\n \\\n",
    "                Candidate Items: \\n{candidate_prompt}\"\n",
    "            try:\n",
    "                rank_list = self.get_list_from_result_cot(rank)\n",
    "                rank_score = self.convert_item_id_to_item_score(rank_list, target, target_score)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                continue\n",
    "            if rank_score == 'Error':\n",
    "                print('Error')\n",
    "                continue\n",
    "            if sorted(set(rank_list)) != sorted(set(candidate)):\n",
    "                print('Mismatch')\n",
    "                continue\n",
    "            sft = {\"instruction\": system_prompt,\n",
    "                   \"input\": user_prompt,\n",
    "                   \"output\": rank}\n",
    "            sft_data.append(sft)\n",
    "\n",
    "        # save to file\n",
    "        with open(save_path + '/sft_data_with_cot.json', 'w') as f:\n",
    "            json.dump(sft_data, f)\n",
    "\n",
    "    def save_rank_results_to_json(self, rank_result_path, system_prompt, save_path='new_data/train', output_file='rank_results_collection.json', candidate_name = \"candidate\"):\n",
    "        \"\"\"\n",
    "        从rank_result文件中提取信息并保存到结构化JSON文件中\n",
    "\n",
    "        Args:\n",
    "            rank_result_path: 排序结果数据文件路径\n",
    "            system_prompt: 系统提示词\n",
    "            save_path: 保存路径\n",
    "            output_file: 输出文件名\n",
    "\n",
    "        Returns:\n",
    "            包含所有用户结果的字典\n",
    "        \"\"\"\n",
    "        output_filepath = os.path.join(save_path, output_file)\n",
    "\n",
    "        # 加载排序结果数据\n",
    "        rank_result_data = pd.read_parquet(rank_result_path)\n",
    "        print(f\"加载了 {len(rank_result_data)} 条数据来自 {rank_result_path}\")\n",
    "\n",
    "        # 加载其他必要数据\n",
    "        meta_data = pd.read_parquet(self.meta_data_path)\n",
    "        test_data = pd.read_parquet(self.test_data_path)\n",
    "        images_data = pd.read_parquet(save_path + '/image_text.parquet')\n",
    "\n",
    "        # 检查是否存在现有文件，如果存在则加载\n",
    "        if os.path.exists(output_filepath):\n",
    "            with open(output_filepath, 'r', encoding='utf-8') as f:\n",
    "                try:\n",
    "                    results_collection = json.load(f)\n",
    "                    print(f\"加载了现有的结果集合，包含 {len(results_collection)} 个用户\")\n",
    "                    # print(results_collection[\"50\"])\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"现有文件格式错误，创建新的结果集合\")\n",
    "                    results_collection = {}\n",
    "        else:\n",
    "            results_collection = {}\n",
    "            print(f\"创建新的结果集合\")\n",
    "\n",
    "        # 确保保存路径存在\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "        for i, row in tqdm(rank_result_data.iterrows(), total=len(rank_result_data), desc=\"处理用户\"):\n",
    "            user_id = str(row['user_id'])\n",
    "            if results_collection.get(user_id) is None:\n",
    "                rank = row['rank_result']\n",
    "                target = row['target']\n",
    "                target_score = row['target_score']\n",
    "                candidate = test_data[test_data['user_id'] == int(user_id)][candidate_name].values[0]\n",
    "                candidate_prompt, candidate_num, target, target_score = self.get_candidate_prompt_for_one_user(int(user_id), meta_data, test_data, images_data)\n",
    "                user_preference_prompt = test_data[test_data['user_id'] == int(user_id)]['user_preference'].values[0]\n",
    "                user_prompt = f\"Please rank the following {candidate_num} items based on user's preference and give back your answer with a form of list of these candidate items'ID :\\n \\\n",
    "                    User Preference: {user_preference_prompt} \\n \\\n",
    "                    Candidate Items: \\n{candidate_prompt}\"\n",
    "\n",
    "                try:\n",
    "                    rank_list = self.get_list_from_result_cot(rank)\n",
    "                    rank_score = self.convert_item_id_to_item_score(rank_list, target, target_score)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "\n",
    "                if rank_score == 'Error':\n",
    "                    rank_answer = 'Error'\n",
    "                elif sorted(rank_list) != sorted(candidate):\n",
    "                    rank_answer = 'Mismatch'\n",
    "                else:\n",
    "                    rank_answer = ndcg_at_k(rank_score, 10)\n",
    "                results_collection[user_id] = {\"prompt\": system_prompt + \"\\n\" + user_prompt, \"target\": str(target), \"rank1\": {\"answer\": rank, \"score\": rank_answer}}\n",
    "\n",
    "            else:\n",
    "                rank = row['rank_result']\n",
    "                target = row['target']\n",
    "                target_score = row['target_score']\n",
    "                candidate = test_data[test_data['user_id'] == int(user_id)][candidate_name].values[0]\n",
    "\n",
    "                try:\n",
    "                    rank_list = self.get_list_from_result_cot(rank)\n",
    "                    rank_score = self.convert_item_id_to_item_score(rank_list, target, target_score)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "\n",
    "                if rank_score == 'Error':\n",
    "                    rank_answer = 'Error'\n",
    "                elif sorted(set(rank_list)) != sorted(set(candidate)):\n",
    "                    rank_answer = 'Mismatch'\n",
    "                else:\n",
    "                    rank_answer = ndcg_at_k(rank_score, 10)\n",
    "                # n 是当前的rank数\n",
    "                n = len(results_collection[user_id])-1\n",
    "                # print(n)\n",
    "                results_collection[user_id][f\"rank{n}\"] = {\"answer\": rank, \"score\": rank_answer}\n",
    "\n",
    "        # 保存到文件\n",
    "        with open(output_filepath, 'w', encoding='utf-8') as f:\n",
    "            json.dump(results_collection, f)\n",
    "\n",
    "        print(f\"保存了 {len(results_collection)} 个用户的排序结果到 {output_filepath}\")\n",
    "\n",
    "    def get_dpo_data_from_collection(self, rank_results_collection_path, save_path='new_data/train'):\n",
    "        \"\"\"\n",
    "        从rank_results_collection.json生成DPO训练数据\n",
    "        将有数字分数的结果作为chosen，没有数字分数的结果作为rejected\n",
    "        \n",
    "        Args:\n",
    "            rank_results_collection_path: 排序结果集合的文件路径\n",
    "            save_path: DPO数据保存路径\n",
    "        \n",
    "        Returns:\n",
    "            生成的DPO数据列表\n",
    "        \"\"\"\n",
    "        # 确保保存路径存在\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        \n",
    "        # 加载排序结果集合\n",
    "        try:\n",
    "            with open(rank_results_collection_path, 'r', encoding='utf-8') as f:\n",
    "                results_collection = json.load(f)\n",
    "            print(f\"加载了 {len(results_collection)} 个用户的排序结果\")\n",
    "        except Exception as e:\n",
    "            print(f\"加载排序结果集合失败: {e}\")\n",
    "            return []\n",
    "        \n",
    "        # 创建DPO数据列表\n",
    "        dpo_data = []\n",
    "        skipped_users = 0\n",
    "        scored_vs_scored = 0\n",
    "        scored_vs_error = 0\n",
    "        total_users = len(results_collection)\n",
    "        \n",
    "        # 遍历所有用户\n",
    "        for user_id, user_data in tqdm(results_collection.items(), desc=\"生成DPO数据\"):\n",
    "            # 获取用户的输入提示\n",
    "            user_prompt = user_data.get(\"prompt\", \"\")\n",
    "            target = user_data.get(\"target\", \"\")\n",
    "            \n",
    "            # 收集所有rank的结果，分为有分数和无分数两组\n",
    "            ranks_with_score = []    # 有数字分数的结果\n",
    "            ranks_without_score = [] # 分数为Error或Mismatch的结果\n",
    "            \n",
    "            # 遍历所有rank键\n",
    "            for key, value in user_data.items():\n",
    "                if key.startswith(\"rank\") and isinstance(value, dict):\n",
    "                    score = value.get(\"score\")\n",
    "                    answer = value.get(\"answer\", \"\")\n",
    "                    \n",
    "                    # 检查score是否为数值\n",
    "                    if isinstance(score, (int, float)) and not isinstance(score, bool):\n",
    "                        ranks_with_score.append({\n",
    "                            \"key\": key,\n",
    "                            \"answer\": answer,\n",
    "                            \"score\": score\n",
    "                        })\n",
    "                    else:\n",
    "                        # 如果分数不是数值（如'Error'或'Mismatch'）\n",
    "                        ranks_without_score.append({\n",
    "                            \"key\": key,\n",
    "                            \"answer\": answer,\n",
    "                            \"score\": score\n",
    "                        })\n",
    "            \n",
    "            # 如果没有有分数的结果，则跳过该用户\n",
    "            if not ranks_with_score:\n",
    "                skipped_users += 1\n",
    "                continue\n",
    "            \n",
    "            # 按分数对有分数的结果排序（从高到低）\n",
    "            sorted_ranks = sorted(ranks_with_score, key=lambda x: x[\"score\"], reverse=True)\n",
    "            \n",
    "            # 获取得分最高的作为chosen\n",
    "            chosen_result = sorted_ranks[0][\"answer\"]\n",
    "            \n",
    "            # 生成DPO样本：每个有分数但非最高分的结果作为一个rejected样本\n",
    "            for i in range(1, len(sorted_ranks)):\n",
    "                rejected_result = sorted_ranks[i][\"answer\"]\n",
    "                \n",
    "                dpo_item = {\n",
    "                    \"input\": user_prompt,\n",
    "                    \"chosen\": chosen_result,\n",
    "                    \"rejected\": rejected_result,\n",
    "                    \"target\": target,\n",
    "                }\n",
    "                scored_vs_scored += 1\n",
    "                dpo_data.append(dpo_item)\n",
    "            \n",
    "            # 所有没有数字分数的结果也作为rejected样本\n",
    "            for item in ranks_without_score:\n",
    "                rejected_result = item[\"answer\"]\n",
    "                \n",
    "                dpo_item = {\n",
    "                    \"input\": user_prompt,\n",
    "                    \"chosen\": chosen_result,\n",
    "                    \"rejected\": rejected_result,\n",
    "                    \"target\": target,\n",
    "                }\n",
    "                scored_vs_error += 1\n",
    "                dpo_data.append(dpo_item)\n",
    "        \n",
    "        # 保存最终结果\n",
    "        if dpo_data:\n",
    "            with open(f\"{save_path}/dpo_data_with_cot.json\", 'w', encoding='utf-8') as f:\n",
    "                json.dump(dpo_data, f, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"DPO数据生成完成，共 {len(dpo_data)} 对样本，跳过了 {skipped_users}/{total_users} 个用户\")\n",
    "        \n",
    "        # 输出不同类型样本的统计\n",
    "        print(f\"有分数 vs 有分数的样本: {scored_vs_scored} 个\")\n",
    "        print(f\"有分数 vs 错误/不匹配的样本: {scored_vs_error} 个\")\n",
    "\n",
    "    def save_rank_result_for_all_users(self, meta_data, test_data, images_data, reason_data, system_prompt, model=\"qwen2.5-7b-instruct-1m\", save_path='new_data', candidate_name=\"candidate\"):\n",
    "        # 为所有用户生成排序结果\n",
    "        rank_results = []\n",
    "        for i in range(len(test_data)):\n",
    "            user_id = test_data.iloc[i]['user_id']\n",
    "            print('user_id:', user_id)\n",
    "            try:\n",
    "                result, target, target_score = self.get_rank_result_for_one_user(user_id, meta_data, test_data, images_data, reason_data, system_prompt, candidate_name, model)\n",
    "                print(result)\n",
    "                rank_results.append([user_id, result, target, target_score])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                rank_results.append('None')\n",
    "        # 保存到文件\n",
    "        df = pd.DataFrame(rank_results, columns=['user_id', 'rank_result', 'target', 'target_score'])\n",
    "        df.to_parquet(save_path + '/rank_result_image.parquet')\n",
    "\n",
    "    def save_rank_result_for_all_users_efficient(self, meta_data, test_data, images_data, system_prompt, model=\"qwen2.5-7b-instruct-1m\", save_path='new_data', max_workers=10, candidate_name=\"candidate\"):\n",
    "        \"\"\"\n",
    "        使用并发处理为所有用户生成排序结果\n",
    "\n",
    "        Args:\n",
    "            meta_data: 物品元数据\n",
    "            test_data: 测试数据\n",
    "            images_data: 图像文本数据\n",
    "            reason_data: 物品选择原因数据\n",
    "            system_prompt: 系统提示词\n",
    "            model: 使用的模型，默认为\"qwen2.5-7b-instruct-1m\"\n",
    "            save_path: 保存结果的路径，默认为'new_data'\n",
    "            max_workers: 最大工作线程数，默认为10\n",
    "        \"\"\"\n",
    "        # 创建一个临时函数来处理单个用户\n",
    "        def process_one_user(idx):\n",
    "            user_id = test_data.iloc[idx]['user_id']\n",
    "            try:\n",
    "                result, target, target_score = self.get_rank_result_for_one_user(user_id, meta_data, test_data, images_data, system_prompt, candidate_name, model)\n",
    "                # print(f'用户 {user_id} 处理完成')\n",
    "                return [user_id, result, target, target_score]\n",
    "            except Exception as e:\n",
    "                print(f'用户 {user_id} 处理出错: {e}')\n",
    "                return [user_id, 'None', -1, -1]\n",
    "\n",
    "        # 使用线程池并发处理\n",
    "        rank_results = []\n",
    "        total_users = len(test_data)\n",
    "\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            # 提交所有任务\n",
    "            future_to_idx = {executor.submit(process_one_user, idx): idx for idx in range(total_users)}\n",
    "\n",
    "            # 使用tqdm显示进度条\n",
    "            for future in tqdm(concurrent.futures.as_completed(future_to_idx), total=total_users, desc=\"处理用户\"):\n",
    "                result = future.result()\n",
    "                rank_results.append(result)\n",
    "\n",
    "        # 保存到文件\n",
    "        df = pd.DataFrame(rank_results, columns=['user_id', 'rank_result', 'target', 'target_score'])\n",
    "        df.to_parquet(save_path + '/rank_result.parquet')\n",
    "        return df\n",
    "\n",
    "    def calculate_ndcg(self, rank_result_path):\n",
    "        rank_result_data = pd.read_parquet(rank_result_path)\n",
    "        ndcg_1 = 0\n",
    "        ndcg_5 = 0\n",
    "        ndcg_10 = 0\n",
    "        for i in range(len(rank_result_data)):\n",
    "            rank = rank_result_data.iloc[i]['rank_result']\n",
    "            target = rank_result_data.iloc[i]['target']\n",
    "            target_score = rank_result_data.iloc[i]['target_score']\n",
    "            rank = self.get_list_from_result(rank)\n",
    "            rank_score = self.convert_item_id_to_item_score(rank, target, target_score)\n",
    "            if rank_score == 'Error':\n",
    "                print('Error')\n",
    "                continue\n",
    "            ndcg_1 += ndcg_at_k(rank_score, 1)\n",
    "            ndcg_5 += ndcg_at_k(rank_score, 5)\n",
    "            ndcg_10 += ndcg_at_k(rank_score, 10)\n",
    "        print('ndcg@1:', ndcg_1/len(rank_result_data))\n",
    "        print('ndcg@5:', ndcg_5/len(rank_result_data))\n",
    "        print('ndcg@10:', ndcg_10/len(rank_result_data))\n",
    "\n",
    "    def convert_img_description_to_label(self, description, system_prompt, model = \"qwen-max\"):\n",
    "        # 将图像描述转换为标签\n",
    "        result = self.client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"system\", \"content\": system_prompt},\n",
    "                      {\"role\": \"user\", \"content\": description},\n",
    "                      ])\n",
    "        return result.choices[0].message.content\n",
    "    \n",
    "    def convert_img_description_to_label_for_all(self, img_path, system_prompt, model = \"qwen-max\", save_path='new_data'):\n",
    "        # 把原本的图像描述转换为标签，保存到文件中\n",
    "        img_description = pd.read_parquet(img_path)\n",
    "        result = []\n",
    "        for i in tqdm(range(len(img_description)), desc=\"处理图像描述\"):\n",
    "            description = img_description.iloc[i]['image_text']\n",
    "            if description == 'None':\n",
    "                result.append('None')\n",
    "                continue\n",
    "            try:\n",
    "                label = self.convert_img_description_to_label(description, system_prompt, model)\n",
    "                # print(label)\n",
    "                result.append(label)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                result.append('None')\n",
    "        # 保存到文件\n",
    "        img_description['image_label'] = result\n",
    "        img_description.to_parquet(save_path + '/image_label.parquet')\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta_data_path='video_data/train/meta_data.parquet'\n",
    "# review_data_path='video_data/train/review_data.parquet'\n",
    "# test_data_path='video_data/train/test_data.parquet'\n",
    "# meta_data_path='video_data/test/meta_data.parquet'\n",
    "# review_data_path='video_data/test/review_data.parquet'\n",
    "# test_data_path='video_data/test/test_data.parquet'\n",
    "\n",
    "# meta_data_path='new_data/train/meta_data.parquet'\n",
    "# review_data_path='new_data/train/review_data.parquet'\n",
    "# test_data_path='new_data/train/test_data.parquet'\n",
    "# meta_data_path='new_data/test/meta_data.parquet'\n",
    "# review_data_path='new_data/test/review_data.parquet'\n",
    "# test_data_path='new_data/test/test_data.parquet'\n",
    "\n",
    "meta_data_path='cd_data/train/meta_data.parquet'\n",
    "review_data_path='cd_data/train/review_data.parquet'\n",
    "test_data_path='cd_data/train/test_data.parquet'\n",
    "# meta_data_path='cd_data/test/meta_data.parquet'\n",
    "# review_data_path='cd_data/test/review_data.parquet'\n",
    "# test_data_path='cd_data/test/test_data.parquet'\n",
    "\n",
    "api_key = \"\"\n",
    "base_url = \"\"\n",
    "data_processor = Data_Processor(meta_data_path, review_data_path, test_data_path, api_key, base_url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_2_test_system_prompt = \"Now you are a goods decoration expert. You can describe the following goods image in detail but would not spend more than 100 words. Please describe the following goods image.\"\n",
    "img_2_test_user_prompt = \"Please describe the following goods image in a short but detailed way.\"\n",
    "\n",
    "sum_user_preference_system_prompt = \"Now you are a user preference expert. You can summarize the user preference based on the user's history which includes the information of the items and the reviews the user given to the items. Please summarize the user preference based on the user's history and provide a brief summary of it, for example, you can summarize the user's preference, the user's preference is mainly focused on the price, quality, or other aspects, make it concise and clear which should not exceed 80 words.\"\n",
    "\n",
    "rank_candidate_system_prompt = \"Now you are a goods ranker. You can rank the following goods based on user's preference and give back your answer with a form of list of these candidate items'ID. Please rank the following goods based on user's preference and give back your answer with a form of list of these candidate items'ID. For example, if candidate item ids are 1, 2, 3, 4, 5, 6, 7, 8, 9 and 10(number is the item's ID), you must rank them in a form of list such as [3, 6, 1, 4, 10, 2, 7, 8, 9, 5](the order is random, which is just an example). Also, make sure the list contains all the candidate item ids and you have not missed or changed any item id. Please make sure the list is correct and complete based on user's preference and don't need to explain the reason for the ranking.\"\n",
    "rank_candidate_system_prompt_with_cot = \"\"\"\n",
    "Now you are a goods ranker. You can rank the following goods based on user's preference and give back your answer with a form of list of these candidate items'ID and some reasonable thinking steps.\n",
    "You have to give back your thinking steps. However, your thinking steps should be refining, short and complete.\n",
    "You can do it step by step, for example, you can provide the following thinking steps:\n",
    "step1 : From the candidate items, find out all the item ids which are to be ranked.\n",
    "step2 : Think about the user's preference, and analyze the items based on it.\n",
    "step3 : Rank the items based on the user's preference. Give back your answer with the item's ID in a form of list. Remember, all the candidate item ids you find in step1 should be included in the ranked items list, and you have not missed or changed any of them.\n",
    "\n",
    "Example output:\n",
    "step1 : all the item ids are [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "step2 :\n",
    "From the user's preference, we can analyze the items based on the following criteria:\n",
    "1. **Affordability and Practicality:** Items with lower prices and high ratings are prioritized. Items 2 and 5 are cheap and functional.\n",
    "2. **Cost-Effectiveness:** Items 1 and 6 offer good value for money.\n",
    "3. **Eco-Friendly Options:** Item 1 is noted for its eco-friendly features.\n",
    "4. **Cute Designs:** Item 7 has a cute design.\n",
    "5. **High Ratings:** Items 10 and 7 have high ratings.\n",
    "6. **Reliability:** Items 6 and 4 have consistent reviews indicating reliability.\n",
    "7. **Avoid Unreliable Products:** Items like 8 which had disappointing reviews were ranked lower.\n",
    "(You can provide more detailed reasons for the ranking based on the information provided in the prompt. The above steps are just an example and may not be applicable to the current prompt.)\n",
    "\n",
    "step3 : the ranked items are [2, 5, 1, 6, 4, 9, 7, 10, 8, 3]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processor.save_all_images_to_text(img_2_test_system_prompt, img_2_test_user_prompt, model=\"qwen-vl-plus-latest\", save_path='cd_data/train')\n",
    "data_processor.check_and_save_images_to_text(img_2_test_system_prompt, img_2_test_user_prompt, model=\"qwen-vl-plus-latest\", save_path='cd_data/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processor.summarize_user_preference(sum_user_preference_system_prompt, save_path='cd_data/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processor.save_rank_result_for_all_users_efficient(meta_data=pd.read_parquet(meta_data_path), test_data=pd.read_parquet(test_data_path), images_data=pd.read_parquet('cd_data/image_text.parquet'), \n",
    "                                                        system_prompt=rank_candidate_system_prompt_with_cot, model=\"qwen2.5-7b-instruct\", save_path='cd_data', max_workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_result_data = pd.read_parquet('cd_data/train/rank_result.parquet')\n",
    "\n",
    "ndcg_1 = 0\n",
    "ndcg_5 = 0\n",
    "ndcg_10 = 0\n",
    "a = 0\n",
    "\n",
    "error_num = 0\n",
    "for i in range(len(rank_result_data)):\n",
    "    user_id = rank_result_data.iloc[i]['user_id']\n",
    "    rank = rank_result_data.iloc[i]['rank_result']\n",
    "    target = rank_result_data.iloc[i]['target']\n",
    "    target_score = rank_result_data.iloc[i]['target_score']\n",
    "    try:\n",
    "        rank_list = data_processor.get_list_from_result_cot(rank)\n",
    "        rank_score = data_processor.convert_item_id_to_item_score(rank_list, target, target_score)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    if rank_score == 'Error' or len(rank_list) < 9:\n",
    "        error_num += 1\n",
    "        continue\n",
    "    ndcg_1 += ndcg_at_k(rank_score, 1)\n",
    "    ndcg_5 += ndcg_at_k(rank_score, 5)\n",
    "    ndcg_10 += ndcg_at_k(rank_score, 10)\n",
    "print('ndcg@1:', ndcg_1/len(rank_result_data))\n",
    "print('ndcg@5:', ndcg_5/len(rank_result_data))\n",
    "print('ndcg@10:', ndcg_10/len(rank_result_data))\n",
    "print('valid_rate:', (1 - error_num/len(rank_result_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processor.save_candidate_to_test_data(len_meta_data=711, is_shuffle=True, name='candidate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processor.get_sft_data_for_all_user(meta_data=pd.read_parquet(meta_data_path), test_data=pd.read_parquet(test_data_path), images_data=pd.read_parquet('cd_data/train/image_text.parquet'), system_prompt=rank_candidate_system_prompt_with_cot, rank_result_data=pd.read_parquet('cd_data/train/rank_result.parquet'), save_path='cd_data/train/sft_data_with_cot.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processor.save_rank_results_to_json(rank_result_path='cd_data/train/rank_result1_1.parquet', system_prompt=rank_candidate_system_prompt_with_cot, \n",
    "                                         save_path='cd_data/train', output_file='rank_results_collection_c1.json', candidate_name=\"candidate1\")\n",
    "data_processor.save_rank_results_to_json(rank_result_path='cd_data/train/rank_result1_2.parquet', system_prompt=rank_candidate_system_prompt_with_cot, \n",
    "                                         save_path='cd_data/train', output_file='rank_results_collection_c1.json', candidate_name=\"candidate1\")\n",
    "data_processor.get_dpo_data_from_collection(rank_results_collection_path='cd_data/train/rank_results_collection_c1.json', save_path='cd_data/train')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
